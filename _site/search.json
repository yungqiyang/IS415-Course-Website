[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415 Course Website",
    "section": "",
    "text": "Hello everybody, my name is Qi Yang and this is my progress through IS415 - Geospatial Analytics and Applications!"
  },
  {
    "objectID": "Take-Home_Exercise/Take-Home_Exercise_01/Take-Home_Exercise_01.html",
    "href": "Take-Home_Exercise/Take-Home_Exercise_01/Take-Home_Exercise_01.html",
    "title": "Take-Home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab’s hailing services in Singapore",
    "section": "",
    "text": "Loading the necessary R-packages\nThe following R-packages and their use case are as follows:\n\narrow: The Grab-Posisi datasets are stored in snappy.parquet format, so we will need to leverage upon the arrow package to read and write these data.\ntidyverse: To allow us to investigate, manipulate and write the datasets of interest in a readable manner. Also has great compatibility with sf objects.\nlubridate: To handle time format data and conversion of other data types into time formats.\nsf: Allows us to handle spatial data, specifically the master plan subzone and OpenStreetMap road network data.\nspatstat: Used to compute the Clark-Evan’s test and various Kernel Density Estimates in this report.\nmaptools: Dependency for spatstat.\ntmap: For visualisation of the spatial data.\nhtmlwidgets: Used to save interactive spatial data visualisations as HTML widgets to lessen the burden on Quarto when rendering.\n\nThe p_load() functionfrom the pacman package is used to load the libraries and automatically install them for the user if they aren’t already installed.\n\n\nReveal Code\npacman::p_load(sf, tidyverse, arrow, lubridate, tmap, maptools, spatstat, spNetwork, htmlwidgets)\n\n\n\n\nImporting the datasets of interest\nFor this report, 3 different datasets are of interest. Grab-Posisi (parquet) from Grab to obtain the spatial events of Grab trips, MPSZ2019 (shp)from data.gov.sg to provide us with the geographical boundaries for our analysis and gis_osm_roads_free_1 (shp) from OpenStreetMap to obtain the road networks for analysis.\n\nGrab-Posisi Data:\nThe Grab-Posisi data is contained within 10 compartmentalised parquet files, thus, the read_parquet() function from the Arrow package is required. The files are loaded iteratively in a loop and immediately appended to each other without assignment using the bind_rows() function.\n\n\nReveal Code\ngrab_df &lt;- read_parquet(\"Data/Geospatial/GrabPosisi/part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet\")\n\nfor (i in 1:9) {\n  grab_df &lt;- grab_df %&gt;%\n    bind_rows(read_parquet(paste0(\"Data/Geospatial/GrabPosisi/part-0000\", as.character(i), \"-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet\")))\n}\n\n\nWe can see that the Grab-Posisi dataset in its entirety at 30+ million rows is way too large for computation.\n\n\nReveal Code\nglimpse(grab_df)\n\ngrab_df$pingtimestamp &lt;- as_datetime(grab_df$pingtimestamp)\n\n\n\nWe will store the compiled Grab-Posisi just in case there is a need for its entirety in the future as there is spare memory on my drive for now.\n\n\nReveal Code\nwrite_parquet(grab_df, \"Data/Geospatial/GrabPosisi/Grab_Posisi.parquet\")\n\n\nLuckily, as we are interested only in the analysis of the origins of Grab calls in Singapore, the Grab-Posisi data can be subset to reduce its size in the R-Environment to the necessary only. This is achieved using the group_by() function to sort each trip record by its ping time-stamp within the trip itself only. filter() is used to extract only the earliest, and therefore, the origin record while mutate() is used to extract the day of the week in which the trip occurred. The result is stored as an R-Data Structure (RDS) file using the write_rds() function to avoid re-computation in the future.\n\n\nReveal Code\ngrab_origin_df &lt;- grab_df %&gt;% \n  group_by(trj_id) %&gt;% \n  arrange(pingtimestamp) %&gt;% \n  filter(row_number() == 1) %&gt;% \n  mutate(weekday = wday(pingtimestamp, label = TRUE, abbr = TRUE))\n\nglimpse(grab_origin_df)\n\npaste(\"From:\", min(grab_origin_df$pingtimestamp), \"To:\", max(grab_origin_df$pingtimestamp))\n\nwrite_rds(grab_origin_df, \"Data/Geospatial/RDS/Grab_Origins_Posisi.rds\")\n\n\n\nFrom a glimpse() of the subset data, we can see that the data set has been reduced considerably to 28,000 rows. This is still too large for kernel density estimations for my computer to handle, but for data wrangling and investigation purposes, it is good enough. As such, we will not rush to remove columns in case there is a need for them later especially as the main constraint in spatial computations is the number of events in the data.\n\nAdditionally, we can see that the data exists for 14 days only between 8th April 2019 and 21st April 2019.\nWe save this subset data so that the code may be re-run in the future without going through the costly process of compiling and subsetting again.\n\n\nReveal Code\ngrab_origin_df &lt;- read_rds(\"Data/Geospatial/RDS/Grab_Origins_Posisi.rds\")\n\n\n\n\nSingapore Master Plan Subzone and Road Network Data\nBoth the Singapore Master Plan Subzone (mpsz) and Road Network Data are spatial data which require the sf package to read in order to retain the spatial information contained. As such, we will use the st_read() function to read the data, and apply the st_transform() function to cast them to a consistent coordinate reference system (CRS) so that we may apply spatial analysis across both data. The CRS we will use is SVY21, which is specific for Singapore.\nThe Singapore Master Plan Subzone is loaded into the R-Environment below:\n\n\nReveal Code\nmpsz2019 &lt;- \n  st_read(\"Data/Geospatial/MPSZ-2019\", layer = \"MPSZ-2019\") %&gt;% \n  st_transform(crs = 3414)\n\n\nReading layer `MPSZ-2019' from data source \n  `C:\\Users\\yungq\\Desktop\\SMU Modules\\Y4S1\\Geospatial Analysis and Applications\\IS415 Course Website\\Take-Home_Exercise\\Take-Home_Exercise_01\\Data\\Geospatial\\MPSZ-2019' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nReveal Code\nsummary(mpsz2019)\n\n\n  SUBZONE_N          SUBZONE_C          PLN_AREA_N         PLN_AREA_C       \n Length:332         Length:332         Length:332         Length:332        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n   REGION_N           REGION_C                  geometry  \n Length:332         Length:332         MULTIPOLYGON :332  \n Class :character   Class :character   epsg:3414    :  0  \n Mode  :character   Mode  :character   +proj=tmer...:  0  \n\n\nFrom the summary() of the data, we can see that it contains spatial polygon features, originally projected in WGS84, and we were successful in transforming the CRS to SVY21 (or EPSG: 3414 equivalently).\nPlotting the Master-Plan Subzone geospatial data with tmap’s tm_polygons() function for visualisation:\n\n\nReveal Code\nmpsz2019_plot &lt;- mpsz2019 %&gt;%\n  tm_shape() +\n  tm_polygons(col = \"lightyellow\", border.col = \"navy\") +\n  tm_layout(main.title = \"Singapore Master Plan Boundaries 2019\", main.title.size = 1) + tm_compass(size = 1)\n\ntmap_save(tm = mpsz2019_plot, \"Screenshots/mpsz2019.png\")\n\n\n\nThe OpenStreetMap (OSM) Road is loaded into the R-Environment below:\n\n\nReveal Code\nroads &lt;-\n  st_read(\"Data/Geospatial/OSM\", layer = \"gis_osm_roads_free_1\") %&gt;%\n  st_transform(crs = 3414)\n\nsummary(roads)\n\n\n\nHere, the data contains spatial linestrings, and like the mpsz data, is originally projected using WGS84 and successfully converted to SVY21. Also, although we know from the data source that the OSM road networks encompasses Singapore, Brunei and Malaysia, we can also tell from the R-outputs that it extends beyond Singapore’s borders. Compared to the mpsz data, its bounding box is clearly further extending. This also explains the vast number of features the data contains and its long reading time.\nIn the interest of computation times, we will subset the road networks to Singapore’s borders only. To do so, first we generate the Singaporean borders as a spatial polygon object using the st_union() function. We then employ the st_intersection() function on the generated outline of Singapore and the OSM road network to obtain the Singaporean road network only.\nFirst, the coastal outline of Singapore is generated, and its result is saved as an RDS file with the write_rds() function to again avoid re-generation in the future.\n\n\nReveal Code\ncoastal_outline &lt;- st_union(mpsz2019)\n\nwrite_rds(coastal_outline, \"Data/Geospatial/RDS/coastal_outline_sg.rds\")\n\n\n\n\nReveal Code\ncoastal_outline &lt;- read_rds(\"Data/Geospatial/RDS/coastal_outline_sg.rds\")\n\n\n\n\nReveal Code\nsg_coastal_outline_plot &lt;- tm_shape(coastal_outline) +\n  tm_polygons(col = \"white\", border.col = \"red\", lwd = 1.7) +\n  tm_layout(\"Coastal Outine of Singapore 2019\")\n\ntmap_save(sg_coastal_outline_plot, \"Screenshots/sg_coastal_outline_plot.png\")\n\n\n\nNext, we subset the OSM road networks by using the st_intersection() function to constrict the spatial line objects to those within the coastal boundaries of Singapore as generated. Considering the long computation time due to the size of the OSM data, we will save the constricted road network as an RDS file.\n\n\nReveal Code\nroads_sg &lt;- st_intersection(coastal_outline, roads)\n\nwrite_rds(roads_sg, \"Data/Geospatial/RDS/sg_road_network.rds\")\n\n\n\n\nReveal Code\nroads_sg &lt;- read_rds(\"Data/Geospatial/RDS/sg_road_network.rds\")\n\n\nVisualising the generated Singapore road networks with tmap using\n\n\nReveal Code\nmpsz_w_roads2019_plot &lt;-\n  tm_shape(coastal_outline) +\n  tm_polygons(col = \"lightyellow\", border.col = \"red\", border.alpha = 0.6) + tm_layout(main.title = \"Singapore Road Network 2019\", main.title.size = 1) +\n  tm_compass(size = 1) +\n  tm_shape(roads_sg) +\n  tm_lines()\n\ntmap_save(tm = mpsz_w_roads2019_plot, \"Screenshots/mpsz_w_roads2019.png\")\n\n\n\nHere we can observe that there is an extensive road network present outside the mainland of Singapore in the dataset. Thus, we will need to remove them if mainland Singapore is the scope of the study, or if they fall within the scope regardless as they will otherwise affect network contrained kernel density estimates. This is as Grab is unlikely to operate outside the mainland especially on islands like Pulau Tekong, thus, impacting global kernel density estimates because of its low or zero local density.\nFirst though, we should investigate the Grab-Posisi Data further as seen prior, we will need to reduce the scope of our analysis so that computations may be completed in a reasonable amount of time.\n\n\nTransforming the Grab-Posisi Data into a simple features object\nTo investigate the Grab-Posisi data, we must first cast it into a simple features object so that R can recognise the coordinate fields in the dataset as spatial and not simply numeric data. The st_as_af() function is used for this purpose, specifying the longitude and latitudes in that order, and the CRS as WGS84 (or EPSG: 4326 equivalently) as the data are geographical coordinates. The CRS of the data is then transformed into SVY21 format using the st_transform() function by specifying the crs parameter to be 3414, the EPSG code for SVY21.\n\n\nReveal Code\ngrab_origin_sf &lt;- grab_origin_df %&gt;%\n  st_as_sf(coords = c(\"rawlng\", \"rawlat\"), crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\nsummary(grab_origin_sf)\n\n\n    trj_id          driving_mode          osname         \n Length:28000       Length:28000       Length:28000      \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n pingtimestamp                        speed           bearing     \n Min.   :2019-04-08 00:09:26.00   Min.   :-1.000   Min.   :  0.0  \n 1st Qu.:2019-04-11 08:48:29.25   1st Qu.: 3.590   1st Qu.: 90.0  \n Median :2019-04-15 00:08:48.00   Median : 9.945   Median :179.0  \n Mean   :2019-04-14 21:29:59.93   Mean   : 9.566   Mean   :172.5  \n 3rd Qu.:2019-04-18 10:47:59.25   3rd Qu.:14.550   3rd Qu.:256.0  \n Max.   :2019-04-21 23:33:28.00   Max.   :30.949   Max.   :359.0  \n                                                                  \n    accuracy       weekday             geometry    \n Min.   :  1.000   Sun:3983   POINT        :28000  \n 1st Qu.:  3.900   Mon:3975   epsg:3414    :    0  \n Median :  6.000   Tue:4008   +proj=tmer...:    0  \n Mean   :  7.617   Wed:4016                        \n 3rd Qu.: 10.000   Thu:4008                        \n Max.   :728.000   Fri:4002                        \n                   Sat:4008                        \n\n\nWe can see from a the summary of the data that the casting of the grab origins data to a simple features object is successful and that a spatial point geometry column has been added to the data in place of “rawlng” and “rawlat”.\n\n\nTransforming the Grab-Posisi data further into Spatial Points, generic sp and ppp objects\nAs we are using the spatstat package, we will need to cast our Grab trip origins events data from a simple features (sf) object to a planar point pattern (ppp) object to work with it.\nTo do so, we can utilise the as_Spatial() function from the sf package to first convert it into a spatial point dataframe which can then be further transformed to a generic sp object using the as() from the same package by specifying the object class to be “SpatialPoints”. This is required to safely convert an sf object to a ppp object as the as() function does not support casting an sf object to a ppp object directly. The resulting sp object is then computed as a ppp object using the as() function but this time specifying the new object class to be “ppp”.\nThe transformation process and a summary of each casting step are as follows:\n\n\nReveal Code\ngrab_origin_spatial &lt;- grab_origin_sf %&gt;%\n  as_Spatial()\n\nsummary(grab_origin_spatial)\n\n\nObject of class SpatialPointsDataFrame\nCoordinates:\n                min      max\ncoords.x1  3628.243 49845.23\ncoords.x2 25198.140 49689.64\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0\n+units=m +no_defs]\nNumber of points: 28000\nData attributes:\n    trj_id          driving_mode          osname         \n Length:28000       Length:28000       Length:28000      \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n pingtimestamp                        speed           bearing     \n Min.   :2019-04-08 00:09:26.00   Min.   :-1.000   Min.   :  0.0  \n 1st Qu.:2019-04-11 08:48:29.25   1st Qu.: 3.590   1st Qu.: 90.0  \n Median :2019-04-15 00:08:48.00   Median : 9.945   Median :179.0  \n Mean   :2019-04-14 21:29:59.93   Mean   : 9.566   Mean   :172.5  \n 3rd Qu.:2019-04-18 10:47:59.25   3rd Qu.:14.550   3rd Qu.:256.0  \n Max.   :2019-04-21 23:33:28.00   Max.   :30.949   Max.   :359.0  \n                                                                  \n    accuracy       weekday   \n Min.   :  1.000   Sun:3983  \n 1st Qu.:  3.900   Mon:3975  \n Median :  6.000   Tue:4008  \n Mean   :  7.617   Wed:4016  \n 3rd Qu.: 10.000   Thu:4008  \n Max.   :728.000   Fri:4002  \n                   Sat:4008  \n\n\nReveal Code\ngrab_origin_sp &lt;- grab_origin_spatial %&gt;%\n  as(\"SpatialPoints\")\n\nsummary(grab_origin_sp)\n\n\nObject of class SpatialPoints\nCoordinates:\n                min      max\ncoords.x1  3628.243 49845.23\ncoords.x2 25198.140 49689.64\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0\n+units=m +no_defs]\nNumber of points: 28000\n\n\nReveal Code\ngrab_origin_ppp &lt;- grab_origin_sp %&gt;%  \n  as(\"ppp\")\n\nsummary(grab_origin_ppp)\n\n\nPlanar point pattern:  28000 points\nAverage intensity 2.473666e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [3628.24, 49845.23] x [25198.14, 49689.64] units\n                    (46220 x 24490 units)\nWindow area = 1131920000 square units\n\n\n\n\n\nVisualising the Grab-Posisi origins data in interactive view\nTo visualise the Grab trip origins data we prepared, we can use the tm_dots() function. Additionally, as there are 28,000 event points located on a relatively small geographical area, we can expect the points to be dense enough such that we are likely to see clusters without being able to visually make out their densities or individual points.\nTo help with this problem, we can visualise the data using an interactive map style so that we may zoom into specific areas and reduce the density of our visualisation. Normally this can be achieved by specifying tmap_mode() to “view” but as such visualisations are large and computationally expensive, it is in our interest to build the in R and embed them as a HTML widget thus, avoiding building them during the render process. To do so, we leave it in “plot” mode in order to transform them to a leaflet object using the tmap_leaflet() function. The resulting leaflet object can then be saved as a HTML widget using the saveWidget() function from the htmlwidgets package.\n\n\nReveal Code\ngrab_origins_interactive &lt;- tm_shape(grab_origin_sf) +\n  tm_dots(alpha = 0.4, size = 0.03, col = \"green\") +\n  tm_layout(main.title = \"Grab-Posisi Origin points across Singapore\")\n\ngrab_origins_interactive = tmap_leaflet(grab_origins_interactive)\n\nsaveWidget(widget = grab_origins_interactive, file = \"Screenshots/grab_origins_interactive.html\")\n\n\n\n\n\n\nIf we zoom in, it appears that there are little to no overlaps of point coordinates in the data. This is to be expected for 2 reasons. First, pick-up locations are unlikely to fall in the exact same location especially when collected for 2 weeks only. Secondly, the data is very precise (to the cm) when considering that it exists on a country-wide scale. We know this as the data is precise to 2 decimal places when converted to SVY21 and SVY21 geographical points are listed in meters.\nTo be sure, we can use the following code to check for duplicated points.\n\n\nReveal Code\nany(duplicated(grab_origin_ppp))\n\n\n[1] FALSE\n\n\nThis is a good finding as it confirms that there is no need to account for point duplication in the dataset.\nNow, we need to solve the next problem which is the scope of our analysis. To do so, we can look for general point clusters across Singapore which might be of interest to us. A quick visualisation using the coastal outline previously generated as the base layer is performed to help with this.\n\n\nReveal Code\ngrab_origin_sg_plot &lt;- tm_shape(coastal_outline) +\n  tm_polygons(col = \"lightyellow\", border.col = \"blue\", lwd = 1.5) +\n  tm_layout(main.title = \"Origins of Grab Trips in Singapore (within Mainland only)\") +\n  tm_shape(grab_origin_sf) +\n  tm_dots(col = \"darkgreen\", alpha = 0.5)\n\ntmap_save(grab_origin_sg_plot, \"Screenshots/Grab_Origins_SG.png\")\n\n\n\nFrom the darker colouration, it appears that Grab calls in our data were much more concentrated in the central-southern part of Singapore than pretty much any other region. This of course makes sense as that region is where the central business district (CBD) lies, and considering the difference in cost of Grab vs. other forms of public transport, it should be expected that Grab customers are more likely fall within the CBD area especially towards the end of the workday.\nConsidering the size of the Grab origins data and the complexity of the road network, it makes sense to try to limit the area of study so our machines can handle the computations in reasonable time. Considering the spread of the data, the central region is chosen as our area of focus.\n\n\nExtracting the CBD polygons\nUsing the Urban Redevelopment Authority of Singapore’s (URA) definition of the CBD, the planning areas which makes it up are extracted from the mpsz spatial data. These polygons are identified using the “PLN_AREA_N” feature in the data, and extracted using base dataframe splicing methods and the %in% operator in R.\n\n\nReveal Code\ncentral_sg &lt;- mpsz2019[mpsz2019$PLN_AREA_N %in% c(\"DOWNTOWN CORE\", \"MARINA EAST\", \"MARINA SOUTH\", \"MUSEUM\", \"NEWTON\", \"ORCHARD\", \"OUTRAM\", \"RIVER VALLEY\", \"ROCHOR\", \"SINGAPORE RIVER\", \"STRAITS VIEW\"), ]\n\nsummary(central_sg)\n\n\n  SUBZONE_N          SUBZONE_C          PLN_AREA_N         PLN_AREA_C       \n Length:50          Length:50          Length:50          Length:50         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n   REGION_N           REGION_C                  geometry \n Length:50          Length:50          MULTIPOLYGON :50  \n Class :character   Class :character   epsg:3414    : 0  \n Mode  :character   Mode  :character   +proj=tmer...: 0  \n\n\nThe spliced sf object is assigned to central_sg and a summary of the data reveals that it contains 50 spatial polygon objects. Much smaller than the 332 polygon features that were originally in the mpsz dataset.\nTo visualise the new geographical area of study:\n\n\nReveal Code\ncentral_region_plot &lt;- tm_shape(mpsz2019) +\n  tm_polygons(col = \"lightyellow\", border.col = \"navy\") +\n  tm_layout(main.title = \"Central Region of Singapore\") +\n  tm_shape(central_sg) +\n  tm_polygons(col = \"orange\", border.col = \"red\")\n\ntmap_save(central_region_plot, \"Screenshots/central_region_SG.png\")\n\n\n\nFrom the visualisation, we can confirm that the spliced polygons comprises of roughly the area of interest which we identified earlier and that we have reduced the boundaries of our data considerably (much more than the 332 → 50 polygon reduction would suggest).\nAlso, we can confirm that none of Singapore’s outer islands are involved in the focus area we have chosen, and as such we would not need to further narrow down the area to rid of any such polygons.\nAs the focus of the study is the CBD as a whole, and not specific planning areas within the CBD, it makes sense to recomputed the sliced data to consist of the outer boundaries of the CBD only. Like before, the st_union() function is used.\n\n\nReveal Code\ncentral_sg &lt;- st_union(central_sg)\n\n\nA visualisation of the computed boundary polygon can again be visualised by layering it upon the mpsz spatial data using multiple calls to the tm_polygons() function.\n\n\nReveal Code\ncentral_region_SG_outline &lt;- tm_shape(mpsz2019) +\n  tm_polygons(col = \"lightyellow\", border.col = \"navy\") +\n  tm_layout(main.title = \"Central Region of Singapore\") +\n  tm_shape(central_sg) +\n  tm_polygons(col = \"orange\", border.col = \"red\", lwd = 2)\n\ntmap_save(central_region_SG_outline, \"Screenshots/central_region_SG_outline.png\")\n\n\n\n\n\nFiltering down the Grab call origins data to match out study area\nNow that we have dictated the study area for the rest of the study, we will also need to trim down the Grab call origins data that we have. This can be achieve via the st_intersection() function to reduce the data to only those within the boundaries of the central_sg polygon we produced.\nA further interesting point of study might be the difference in calls between the weekends and weekdays. As mentioned in the justification for choosing the CBD as the scope, we expect that most of the Grab call events occur as a result of office workers travelling home. Thus, as most offices are closed on the weekends, it will be interesting to examine the difference in call patterns during the work week vs. the weekends . To do so, we will break the data into 2 parts using the weekday column generated prior to identify calls that fall on the weekends.\n\n\nReveal Code\ngrab_weekend &lt;- grab_origin_sf[grab_origin_sf$weekday %in% c(\"Sun\", \"Sat\"), ]\ngrab_weekday &lt;- grab_origin_sf[!grab_origin_sf$weekday %in% c(\"Sun\", \"Sat\"), ]\n\ncentral_grab_weekend_sf &lt;- st_intersection(grab_weekend, central_sg)\ncentral_grab_weekday_sf &lt;- st_intersection(grab_weekday, central_sg)\n\nsummary(central_grab_weekend_sf)\n\n\n    trj_id          driving_mode          osname         \n Length:698         Length:698         Length:698        \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n pingtimestamp                        speed           bearing     \n Min.   :2019-04-13 00:31:23.00   Min.   :-1.000   Min.   :  0.0  \n 1st Qu.:2019-04-13 16:50:57.00   1st Qu.: 3.417   1st Qu.: 53.0  \n Median :2019-04-14 14:02:41.00   Median : 8.527   Median :172.5  \n Mean   :2019-04-17 02:11:19.36   Mean   : 8.497   Mean   :172.9  \n 3rd Qu.:2019-04-20 15:51:27.25   3rd Qu.:13.170   3rd Qu.:299.0  \n Max.   :2019-04-21 23:25:40.00   Max.   :24.620   Max.   :358.0  \n                                                                  \n    accuracy       weekday            geometry  \n Min.   :  2.000   Sun:308   POINT        :698  \n 1st Qu.:  4.354   Mon:  0   epsg:3414    :  0  \n Median :  8.788   Tue:  0   +proj=tmer...:  0  \n Mean   : 10.932   Wed:  0                      \n 3rd Qu.: 13.490   Thu:  0                      \n Max.   :100.000   Fri:  0                      \n                   Sat:390                      \n\n\nReveal Code\nsummary(central_grab_weekday_sf)\n\n\n    trj_id          driving_mode          osname         \n Length:2335        Length:2335        Length:2335       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n pingtimestamp                        speed           bearing     \n Min.   :2019-04-08 00:09:48.00   Min.   :-1.000   Min.   :  0.0  \n 1st Qu.:2019-04-10 09:36:16.50   1st Qu.: 2.631   1st Qu.: 48.5  \n Median :2019-04-12 22:38:39.00   Median : 7.583   Median :152.0  \n Mean   :2019-04-13 23:06:58.46   Mean   : 7.821   Mean   :166.7  \n 3rd Qu.:2019-04-17 12:29:12.50   3rd Qu.:12.196   3rd Qu.:293.0  \n Max.   :2019-04-19 23:12:41.00   Max.   :26.160   Max.   :359.0  \n                                                                  \n    accuracy       weekday            geometry   \n Min.   :  2.000   Sun:  0   POINT        :2335  \n 1st Qu.:  4.141   Mon:441   epsg:3414    :   0  \n Median :  8.576   Tue:454   +proj=tmer...:   0  \n Mean   : 11.581   Wed:457                       \n 3rd Qu.: 13.000   Thu:540                       \n Max.   :728.000   Fri:443                       \n                   Sat:  0                       \n\n\nA quick examination of the data shows that there were 2335 trips which originated on weekdays, and 698 calls on the weekends. In general, we can also expect around 25 less calls on Saturdays than during the work week and roughly 60 less calls on Sundays. Thursdays also generated the most calls at 540 trip originations happening on thursdays across the 2 weeks.\n\n\nVisualising the origins of Grab trips over the weekends and weekdays in the Central Region of Singapore.\nTo visualise the rough density patterns across the 2 different time periods in the CBD, we can employ the following code:\n\n\nReveal Code\ngrab_central_weekday_plot &lt;- tm_shape(central_sg) +\n  tm_polygons(col = \"lightyellow\", border.col = \"blue\", lwd = 1.5) +\n  tm_layout(main.title = \"Origins of Weekday Grab Trips in Singapore (within Central Region only)\", main.title.size = 0.7) +\n  tm_shape(central_grab_weekday_sf) +\n  tm_dots(col = \"darkgreen\", alpha = 0.3, size = 0.5)\n\ngrab_central_weekend_plot &lt;- tm_shape(central_sg) +\n  tm_polygons(col = \"lightyellow\", border.col = \"blue\", lwd = 1.5) +\n  tm_layout(main.title = \"Origins of Weekend Grab Trips in Singapore (within Central Region only)\", main.title.size = 0.7) +\n  tm_shape(central_grab_weekend_sf) +\n  tm_dots(col = \"darkgreen\", alpha = 0.3, size = 0.5)\n\ntmap_save(grab_central_weekday_plot, \"Screenshots/grab_central_weekday_plot.png\")\n\ntmap_save(grab_central_weekend_plot, \"Screenshots/grab_central_weekend_plot.png\")\n\n\n\n\ntm_dots() is used to identify the Grab trip origins and a reasonably low alpha value is specified to introduce transparency in the visualisation so that areas of denser events will stand out with deeper colours.\nIt appears that on the weekends, calls not only originate from the CBD less often. Although this is neither obvious nor interpretable from the visualisation alone as we are comparing 10 days of data vs. 4 days worth. However, our quick investigation of the spliced data above does make this a reasonable observation to have here.\nAdditionally, it seems also that the geographical patterns in Grab calls also differ on the weekends and weekdays. On the weekdays the Grab trip origins appear to be more evenly distributed whilst being slightly more concentrated in the nothern regions of the CBD on the weekends with barely any calls from the center and southern parts during this period.\n\n\nTransforming the filtered Grab origins data into Spatial Points, generic sp and ppp objects\nAs before with the simple features Grab data we need to transform the data to a ppp object if we want to conduct analysis on it using the spatstats package. To do so:\n\nFor the Weekend:\n\n\nReveal Code\ncentral_grab_weekend_spatial &lt;- central_grab_weekend_sf %&gt;%\n  as_Spatial()\n\nsummary(central_grab_weekend_spatial)\n\n\nObject of class SpatialPointsDataFrame\nCoordinates:\n               min      max\ncoords.x1 26935.13 31786.09\ncoords.x2 27890.04 32876.01\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0\n+units=m +no_defs]\nNumber of points: 698\nData attributes:\n    trj_id          driving_mode          osname         \n Length:698         Length:698         Length:698        \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n pingtimestamp                        speed           bearing     \n Min.   :2019-04-13 00:31:23.00   Min.   :-1.000   Min.   :  0.0  \n 1st Qu.:2019-04-13 16:50:57.00   1st Qu.: 3.417   1st Qu.: 53.0  \n Median :2019-04-14 14:02:41.00   Median : 8.527   Median :172.5  \n Mean   :2019-04-17 02:11:19.36   Mean   : 8.497   Mean   :172.9  \n 3rd Qu.:2019-04-20 15:51:27.25   3rd Qu.:13.170   3rd Qu.:299.0  \n Max.   :2019-04-21 23:25:40.00   Max.   :24.620   Max.   :358.0  \n                                                                  \n    accuracy       weekday  \n Min.   :  2.000   Sun:308  \n 1st Qu.:  4.354   Mon:  0  \n Median :  8.788   Tue:  0  \n Mean   : 10.932   Wed:  0  \n 3rd Qu.: 13.490   Thu:  0  \n Max.   :100.000   Fri:  0  \n                   Sat:390  \n\n\nReveal Code\ncentral_grab_weekend_sp &lt;- central_grab_weekend_spatial %&gt;%\n  as(\"SpatialPoints\")\n\nsummary(central_grab_weekend_sp)\n\n\nObject of class SpatialPoints\nCoordinates:\n               min      max\ncoords.x1 26935.13 31786.09\ncoords.x2 27890.04 32876.01\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0\n+units=m +no_defs]\nNumber of points: 698\n\n\nReveal Code\ncentral_grab_weekend_ppp &lt;- central_grab_weekend_sp %&gt;%\n  as(\"ppp\")\n\nsummary(central_grab_weekend_ppp)\n\n\nPlanar point pattern:  698 points\nAverage intensity 2.885876e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [26935.13, 31786.09] x [27890.04, 32876.01] units\n                    (4851 x 4986 units)\nWindow area = 24186800 square units\n\n\n\n\nFor the Weekdays:\n\n\nReveal Code\ncentral_grab_weekday_spatial &lt;- central_grab_weekday_sf %&gt;%\n  as_Spatial()\n\nsummary(central_grab_weekday_spatial)\n\n\nObject of class SpatialPointsDataFrame\nCoordinates:\n               min      max\ncoords.x1 26902.48 32829.73\ncoords.x2 28050.48 33252.24\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0\n+units=m +no_defs]\nNumber of points: 2335\nData attributes:\n    trj_id          driving_mode          osname         \n Length:2335        Length:2335        Length:2335       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n pingtimestamp                        speed           bearing     \n Min.   :2019-04-08 00:09:48.00   Min.   :-1.000   Min.   :  0.0  \n 1st Qu.:2019-04-10 09:36:16.50   1st Qu.: 2.631   1st Qu.: 48.5  \n Median :2019-04-12 22:38:39.00   Median : 7.583   Median :152.0  \n Mean   :2019-04-13 23:06:58.46   Mean   : 7.821   Mean   :166.7  \n 3rd Qu.:2019-04-17 12:29:12.50   3rd Qu.:12.196   3rd Qu.:293.0  \n Max.   :2019-04-19 23:12:41.00   Max.   :26.160   Max.   :359.0  \n                                                                  \n    accuracy       weekday  \n Min.   :  2.000   Sun:  0  \n 1st Qu.:  4.141   Mon:441  \n Median :  8.576   Tue:454  \n Mean   : 11.581   Wed:457  \n 3rd Qu.: 13.000   Thu:540  \n Max.   :728.000   Fri:443  \n                   Sat:  0  \n\n\nReveal Code\ncentral_grab_weekday_sp &lt;- central_grab_weekday_spatial %&gt;%\n  as(\"SpatialPoints\")\n\nsummary(central_grab_weekday_sp)\n\n\nObject of class SpatialPoints\nCoordinates:\n               min      max\ncoords.x1 26902.48 32829.73\ncoords.x2 28050.48 33252.24\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0\n+units=m +no_defs]\nNumber of points: 2335\n\n\nReveal Code\ncentral_grab_weekday_ppp &lt;- central_grab_weekday_sp %&gt;%\n  as(\"ppp\")\n\nsummary(central_grab_weekday_ppp)\n\n\nPlanar point pattern:  2335 points\nAverage intensity 7.573262e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [26902.48, 32829.73] x [28050.48, 33252.24] units\n                    (5927 x 5202 units)\nWindow area = 30832200 square units\n\n\nAgain, summaries of each casting step are displayed to our purview.\n\n\n\nScaling the ppp objects to “km” for more interpretable patterns when we produce the kernel density estimates\nAs mentioned prior, the data is scaled in meters. This means that when we generate the kernel density estimates (KDE) we will be given densities which suggests that certain areas receive 0.0005 calls per meter2 for instance as we are running a KDE across an entire country. This has very low interpretability, so we should re-scale the data points to km so that we can receive easy to understand density estimates when we conduct KDE.\nTo do so, we rely upon the rescale() function, parsing the conversion rate of 1000 to the function:\n\n\nReveal Code\ncentral_grab_weekend_ppp.km &lt;- rescale(central_grab_weekend_ppp, 1000, \"km\")\n\ncentral_grab_weekday_ppp.km &lt;- rescale(central_grab_weekday_ppp, 1000, \"km\")\n\nsummary(central_grab_weekend_ppp.km)\n\n\nPlanar point pattern:  698 points\nAverage intensity 28.85876 points per square km\n\nCoordinates are given to 6 decimal places\n\nWindow: rectangle = [26.93513, 31.78609] x [27.89004, 32.87601] km\n                    (4.851 x 4.986 km)\nWindow area = 24.1868 square km\nUnit of length: 1 km\n\n\nReveal Code\nsummary(central_grab_weekday_ppp.km)\n\n\nPlanar point pattern:  2335 points\nAverage intensity 75.73262 points per square km\n\nCoordinates are given to 6 decimal places\n\nWindow: rectangle = [26.90248, 32.82973] x [28.05048, 33.25224] km\n                    (5.927 x 5.202 km)\nWindow area = 30.8322 square km\nUnit of length: 1 km\n\n\nSummaries of the Grab trip origins planar point pattern objects now show that the points have successfully been re-scaled to km.\n\n\nUsing the ppl method to conduct the Kernel Density Estimations\nThe ppl method is favoured here because the pre-emptive visualisation showed us that the call origins are generally spread out in multiple clusters over the week. As such, we do not use the diggle bandwidth method as we are not searching for a single cluster within a bunch of noise but rather multiple clusters.\nThe KDE are computed using the density() function from spatstat, specifying bw.ppl for the kernel bandwidth. Especially as there are large clusters near the edge of our project’s geographical boundaries observable from earlier visualisations, it is imperative that we correct for edge bias by specifying it to TRUE.\n\n\nReveal Code\npar(cex.main = 0.7)\n\nkde_central_grab_weekend_ppl_bw.km &lt;- density(central_grab_weekend_ppp.km, sigma=bw.ppl, edge=TRUE, kernel=\"gaussian\")\n\nkde_central_grab_weekday_ppl_bw.km &lt;- density(central_grab_weekday_ppp.km, sigma=bw.ppl, edge=TRUE, kernel=\"gaussian\")\n\nplot(kde_central_grab_weekend_ppl_bw.km, main = \"Scaled Kernel Density Estimate of Grab Trip Origins in Central SG on Weekends (ppl)\")\n\n\n\n\n\n\n\n\n\nReveal Code\nplot(kde_central_grab_weekday_ppl_bw.km, main = \"Scaled Kernel Density Estimate of Grab Trip Origins in Central SG on Weekdays (ppl)\")\n\n\n\n\n\n\n\n\n\nFrom the produced KDE plots, we can confirm that the Grab trip origins are pretty evenly spread out in multiple clusters across the CBD on the weekdays. However, the trips are far more concentrated in the northern half of the CBD than we initially realised, with 2 big hotspots in there which stand out from the rest.\n\n\nUsing the Adaptive Bandwidth method to conduct the Kernel Density Estimations\nAn adaptive bandwidth method can also be applied to our kernel density estimates instead:\n\n\nReveal Code\npar(cex.main = 0.7)\n\nkde_central_grab_weekend_ppp_adaptive &lt;- adaptive.density(central_grab_weekend_ppp.km, method=\"kernel\")\n\nkde_central_grab_weekday_ppp_adaptive &lt;- adaptive.density(central_grab_weekday_ppp.km, method=\"kernel\")\n\nplot(kde_central_grab_weekend_ppp_adaptive, main = \"Kernel Density Estimate of Grab Trip Origins in central SG on weekends (adaptive bandwidth)\")\n\n\n\n\n\n\n\n\n\nReveal Code\nplot(kde_central_grab_weekday_ppp_adaptive, main = \"Kernel Density Estimate of Grab Trip Origins in central SG on weekdays (adaptive bandwidth)\")\n\n\n\n\n\n\n\n\n\nThe adaptive KDE plots tells a similar story to when the ppl bandwidth method was applied. However, this time, the clustering of the origins of Grab trips towards the northern half of the CBD during the weekends are far more evident than before. In fact, when adapative bandwidth is applied, the southern half of the CBD is what can only be described as a cold-spot with barely any purple-ish colouration present. The evidence of multiple but well-spread out clusters across the CBD during the weekdays is more evident here than before as previously it seems like the hot-spots may have been briefly connected, here, the drop-off between each hot-spot is much more obvious.\n\n\nConducting the Clark-Evans test for Spatial Point Pattern\nTo conduct a Clark-Evans’ hypothesis test as to the randomness of the spatial point distribution of Grab trips in the CBD, we can utilise the clarkevans.test() function. Within the function, we can correct for edge bias again, especially now that we know from the KDE that we can expect the data to be heavily concentrated near the top during the weekends. CDF correction method is applied as recommended in the Clark-Evans documentation in R which suggests Donnelly correction for rectangular windows only.\n\n\nReveal Code\nclarkevans.test(central_grab_weekday_ppp.km, correction=\"cdf\", alternative=c(\"clustered\"), nsim=99)\n\n\n\n    Clark-Evans test\n    CDF correction\n    Z-test\n\ndata:  central_grab_weekday_ppp.km\nR = 0.30295, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nReveal Code\nclarkevans.test(central_grab_weekend_ppp.km, correction=\"cdf\", alternative=c(\"clustered\"), nsim=99)\n\n\n\n    Clark-Evans test\n    CDF correction\n    Z-test\n\ndata:  central_grab_weekend_ppp.km\nR = 0.41096, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nFrom the p-values of the Clark-Evan’s test, we have to conclude that the distributions of the Grab trip origins display clustering patterns within Singapore’s CBD regardless of the part of the week. This is a conclusion supported by our KDE plots either using ppl or adaptive bandwidth methods.\n\n\nLimiting the Road Network Data to Central Singapore\nEarlier in this report, we conducted an extraction of the road networks from OpenStreetMap using the st_intersection() function. We will need to do so again as we have since further limited the scope of our study to the CBD. This time however, as the purpose of using the road network data lies in constructing Network-Contrained Kernel Density Estimations, we will need to ensure that only spatial Line features exist in the data. To do so, we can employ the st_cast() function to coerce any other spatial features to Spatial Lines.\n\n\nReveal Code\ncentral_roads &lt;- st_intersection(roads_sg, central_sg)\n\ncentral_roads &lt;- st_cast(central_roads, \"LINESTRING\")\n\nwrite_rds(central_roads, \"Data/Geospatial/RDS/central_road_network.rds\")\n\n\nOnce again we save the spliced data for further use as it is computationally expensive.\n\n\nReveal Code\ncentral_roads &lt;- read_rds(\"Data/Geospatial/RDS/central_road_network.rds\")\n\ncentral_roads &lt;- st_simplify(central_roads, preserveTopology = FALSE)\n\n\n\n\nVisualising the Road Network Data across the CBD\nUsing the tm_lines() function we can build a visual plot of the road networks in the CBD\n\n\nReveal Code\ncentral_road_network_plot &lt;- tm_shape(central_sg) +\n  tm_polygons(col = \"lightyellow\") +\n  tm_layout(main.title = \"Road Network in Central Singapore\") +\n  tm_shape(central_roads) +\n  tm_lines(col = \"brown\")\n\ntmap_save(central_road_network_plot, \"Screenshots/central_road_network.png\")\n\n\n\n\n\nPreparing the lixel objects and generating the line centre points\nIn order to conduct NKDE, we will need to use the spNetwork package which requires that we parse lixel objects rather than sf objects with LINESTRING geometry type. Thus, we need to generate these lixels using the lixelize_lines() function. Additionally, the computation of NKDE also requires that we generate the center points of these lixels. This can be generated by parsing the lixels into the lines_center() function.\n\n\nReveal Code\nlixels &lt;- lixelize_lines(central_roads, 700, mindist = 300)\n\nsamples &lt;- lines_center(lixels)\n\nwrite_rds(lixels, \"Data/Geospatial/RDS/central_road_lixels.rds\")\n\nwrite_rds(samples, \"Data/Geospatial/RDS/central_road_centrepoints.rds\")\n\n\nAs the road network data is quite extensive, the computation of the lixels are extremely computationally expensive and time consuming. Thus, we save the generated lixels and lixel center points as RDS files also.\n\n\nReveal Code\nlixels &lt;- read_rds(\"Data/Geospatial/RDS/central_road_lixels.rds\")\n\nsamples &lt;- read_rds(\"Data/Geospatial/RDS/central_road_centrepoints.rds\")\n\n\n\n\nPerforming the Network Constrained Kernel Density Estimation\nNow that we have prepared the lixels and their center points, we can run the NKDE across our 2 segmented Grab data. Our previous KDE plots provides us with some indicates of the parameters in which we can run our NKDE upon. Firstly, the kernel used should be “quartic” as we are looking for several spikes in the data whilst being less sensitive to outlier events because we know that the southern parts of the CBD are less densely serviced by Grab than the northern parts during the weekends. And even though the data is more evenly spread out in the workweek, the adaptive KDE reveals that the data exists as multiple hot-spots with strong drop-offs rather than a smooth transition to the next hot-spot. We run it on a “simple” method and set sparse to TRUE to reduce computation time, but also set verbose to TRUE to get updated that the process is running properly as the computation is expected to be very time-consuming regardless.\n\nWeekday Data:\nUsing the nkde() function to compute the network-constrained kernel density estimates of the weekday Grab trips in the CBD:\n\n\nReveal Code\nweekday_densities &lt;- nkde(central_roads, \n                          events = central_grab_weekday_sf,  \n                          w = rep(1,nrow(central_grab_weekday_sf)), \n                          samples = samples, \n                          kernel_name = \"quartic\", \n                          bw = 300, \n                          div= \"bw\", \n                          method = \"simple\", \n                          digits = 1, \n                          tol = 1, \n                          grid_shape = c(1,1), \n                          max_depth = 8, \n                          agg = 5, \n                          sparse = TRUE, \n                          verbose = TRUE)\n\nwrite_rds(weekday_densities, \"Data/Geospatial/RDS/Grab_weekday_nkde.rds\")\n\n\nOnce the density estimates are computed, we store them away as RDS files to avoid running them again unless there is a change in the data.\n\n\nReveal Code\nweekday_densities &lt;- read_rds(\"Data/Geospatial/RDS/Grab_weekday_nkde.rds\")\n\nsamples$density &lt;- weekday_densities * 1000\nlixels$density &lt;- weekday_densities * 1000\n\n\nWe then reassign the computed densities to the lixel and lixel center point objects used.\n\n\nVisualising the Network Constrained Kernel Density Estimate of the Weekday Grab Data over an interactive OpenStreetMap layer\nUsing the densities appended to the lixels generated, and the tm_lines() and tm_dots() function, we can visualise the NKDE plots. Furthermore, we shall use tm_basemap(“OpenStreetMap”) as the base layer rather than the central_sg polygons previously used. This will allow us to obtain contextualised information of the hot-spots from the NKDE produced.\n\n\nReveal Code\ngrab_weekday_interactive &lt;-  tm_shape(lixels) +\n  tm_lines(col=\"density\", lwd = 2) +\n  tm_layout(frame = TRUE, main.title = \"Network-Constrained Kernel Density Estimation of Grab Call Origins in the CBD\") +\n  tm_shape(central_grab_weekday_sf) +\n  tm_dots(col = \"green\", alpha = 0.5, size = 0.01) +\n  tm_scale_bar() +\n  tm_basemap(\"OpenStreetMap\")\n\ngrab_weekday_interactive &lt;- tmap_leaflet(grab_weekday_interactive)\n\nsaveWidget(grab_weekday_interactive, \"Screenshots/CBD_grab_weekday_interactive.html\")\n\n\n\n\n\n\n\n\nWeekend Data:\nUsing the nkde() function to compute the network-constrained kernel density estimates of the weekend Grab trips in the CBD:\n\n\nReveal Code\nweekend_densities &lt;- nkde(central_roads,\n                  events = central_grab_weekend_sf,\n                  w = rep(1,nrow(central_grab_weekend_sf)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div= \"bw\",\n                  method = \"simple\",\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = TRUE)\n\nwrite_rds(weekend_densities, \"Data/Geospatial/RDS/Grab_weekend_nkde.rds\")\n\n\n\n\nReveal Code\nweekend_densities &lt;- read_rds(\"Data/Geospatial/RDS/Grab_weekend_nkde.rds\")\n\nsamples$density &lt;- weekend_densities * 1000\nlixels$density &lt;- weekend_densities * 1000\n\n\n\n\nVisualising the Network Constrained Kernel Density Estimate of the Weekend Grab Data over an interactive OpenStreetMap layer\nSimilarly, like in the visualisation of the weekday Grab data, we can visualise the weekend Grab data within the CBD on weekends:\n\n\nReveal Code\ngrab_weekend_interactive &lt;-  tm_shape(lixels) +\n  tm_lines(col=\"density\", lwd = 2) +\n  tm_layout(frame = TRUE) +\n  tm_shape(central_grab_weekend_sf) +\n  tm_dots(col = \"green\", alpha = 0.5, size = 0.01) +\n  tm_scale_bar() +\n  tm_basemap(\"OpenStreetMap\")\n\ngrab_weekend_interactive &lt;- tmap_leaflet(grab_weekend_interactive)\n\nsaveWidget(grab_weekend_interactive, \"Screenshots/CBD_grab_weekend_interactive.html\")"
  },
  {
    "objectID": "In-Class_Exercise/In-Class_Exercise_05/In-Class_Exercise_05.html",
    "href": "In-Class_Exercise/In-Class_Exercise_05/In-Class_Exercise_05.html",
    "title": "In-Class Exercise 5: Global and Local Measures of Spatial Autocorrelation using sfDep methods",
    "section": "",
    "text": "Loading the required R-Packages\n\n\nReveal Code\npacman::p_load(sf, sfdep, sfdep, tidyverse, tmap)\n\n\n\n\nImporting the required datasets into the R-Environment\n\n\nReveal Code\nhunan &lt;- st_read(\"Data/Geospatial/Hunan\", layer = \"Hunan\")\n\n\nReading layer `Hunan' from data source \n  `C:\\Users\\yungq\\Desktop\\SMU Modules\\Y4S1\\Geospatial Analysis and Applications\\IS415 Course Website\\In-Class_Exercise\\In-Class_Exercise_05\\Data\\Geospatial\\Hunan' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nReveal Code\nsummary(hunan)\n\n\n    NAME_2               ID_3          NAME_3           ENGTYPE_3        \n Length:88          Min.   :21098   Length:88          Length:88         \n Class :character   1st Qu.:21125   Class :character   Class :character  \n Mode  :character   Median :21150   Mode  :character   Mode  :character  \n                    Mean   :21150                                        \n                    3rd Qu.:21174                                        \n                    Max.   :21201                                        \n   Shape_Leng       Shape_Area         County                   geometry \n Min.   :0.7722   Min.   :0.02128   Length:88          POLYGON      :88  \n 1st Qu.:2.2533   1st Qu.:0.13669   Class :character   epsg:4326    : 0  \n Median :2.5844   Median :0.18564   Mode  :character   +proj=long...: 0  \n Mean   :2.6057   Mean   :0.19274                                        \n 3rd Qu.:3.0994   3rd Qu.:0.23735                                        \n Max.   :4.5835   Max.   :0.53452                                        \n\n\nReveal Code\nhunan2012 &lt;- read_csv(\"Data/Aspatial/Hunan_2012.csv\")\n\nglimpse(hunan2012)\n\n\nRows: 88\nColumns: 29\n$ County      &lt;chr&gt; \"Anhua\", \"Anren\", \"Anxiang\", \"Baojing\", \"Chaling\", \"Changn…\n$ City        &lt;chr&gt; \"Yiyang\", \"Chenzhou\", \"Changde\", \"Hunan West\", \"Zhuzhou\", …\n$ avg_wage    &lt;dbl&gt; 30544, 28058, 31935, 30843, 31251, 28518, 54540, 28597, 33…\n$ deposite    &lt;dbl&gt; 10967.0, 4598.9, 5517.2, 2250.0, 8241.4, 10860.0, 24332.0,…\n$ FAI         &lt;dbl&gt; 6831.7, 6386.1, 3541.0, 1005.4, 6508.4, 7920.0, 33624.0, 1…\n$ Gov_Rev     &lt;dbl&gt; 456.72, 220.57, 243.64, 192.59, 620.19, 769.86, 5350.00, 1…\n$ Gov_Exp     &lt;dbl&gt; 2703.0, 1454.7, 1779.5, 1379.1, 1947.0, 2631.6, 7885.5, 11…\n$ GDP         &lt;dbl&gt; 13225.0, 4941.2, 12482.0, 4087.9, 11585.0, 19886.0, 88009.…\n$ GDPPC       &lt;dbl&gt; 14567, 12761, 23667, 14563, 20078, 24418, 88656, 10132, 17…\n$ GIO         &lt;dbl&gt; 9276.90, 4189.20, 5108.90, 3623.50, 9157.70, 37392.00, 513…\n$ Loan        &lt;dbl&gt; 3954.90, 2555.30, 2806.90, 1253.70, 4287.40, 4242.80, 4053…\n$ NIPCR       &lt;dbl&gt; 3528.3, 3271.8, 7693.7, 4191.3, 3887.7, 9528.0, 17070.0, 3…\n$ Bed         &lt;dbl&gt; 2718, 970, 1931, 927, 1449, 3605, 3310, 582, 2170, 2179, 1…\n$ Emp         &lt;dbl&gt; 494.310, 290.820, 336.390, 195.170, 330.290, 548.610, 670.…\n$ EmpR        &lt;dbl&gt; 441.4, 255.4, 270.5, 145.6, 299.0, 415.1, 452.0, 127.6, 21…\n$ EmpRT       &lt;dbl&gt; 338.0, 99.4, 205.9, 116.4, 154.0, 273.7, 219.4, 94.4, 174.…\n$ Pri_Stu     &lt;dbl&gt; 54.175, 33.171, 19.584, 19.249, 33.906, 81.831, 59.151, 18…\n$ Sec_Stu     &lt;dbl&gt; 32.830, 17.505, 17.819, 11.831, 20.548, 44.485, 39.685, 7.…\n$ Household   &lt;dbl&gt; 290.4, 104.6, 148.1, 73.2, 148.7, 211.2, 300.3, 76.1, 139.…\n$ Household_R &lt;dbl&gt; 234.5, 121.9, 135.4, 69.9, 139.4, 211.7, 248.4, 59.6, 110.…\n$ NOIP        &lt;dbl&gt; 101, 34, 53, 18, 106, 115, 214, 17, 55, 70, 44, 84, 74, 17…\n$ Pop_R       &lt;dbl&gt; 670.3, 243.2, 346.0, 184.1, 301.6, 448.2, 475.1, 189.6, 31…\n$ RSCG        &lt;dbl&gt; 5760.60, 2386.40, 3957.90, 768.04, 4009.50, 5220.40, 22604…\n$ Pop_T       &lt;dbl&gt; 910.8, 388.7, 528.3, 281.3, 578.4, 816.3, 998.6, 256.7, 45…\n$ Agri        &lt;dbl&gt; 4942.253, 2357.764, 4524.410, 1118.561, 3793.550, 6430.782…\n$ Service     &lt;dbl&gt; 5414.5, 3814.1, 14100.0, 541.8, 5444.0, 13074.6, 17726.6, …\n$ Disp_Inc    &lt;dbl&gt; 12373, 16072, 16610, 13455, 20461, 20868, 183252, 12379, 1…\n$ RORP        &lt;dbl&gt; 0.7359464, 0.6256753, 0.6549309, 0.6544614, 0.5214385, 0.5…\n$ ROREmp      &lt;dbl&gt; 0.8929619, 0.8782065, 0.8041262, 0.7460163, 0.9052651, 0.7…\n\n\nReveal Code\nhunanGDPPC &lt;- read_csv(\"Data/Aspatial/Hunan_GDPPC.csv\")\n\nglimpse(hunanGDPPC)\n\n\nRows: 1,496\nColumns: 3\n$ Year   &lt;dbl&gt; 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 200…\n$ County &lt;chr&gt; \"Longshan\", \"Changsha\", \"Wangcheng\", \"Ningxiang\", \"Liuyang\", \"Z…\n$ GDPPC  &lt;dbl&gt; 3469, 24612, 14659, 11687, 13406, 8546, 10944, 8040, 7383, 1168…\n\n\n\nAppending the Hunan Aspatial data to the Hunan Geospatial sf object\n\n\nReveal Code\nhunan_GDPPC &lt;- left_join(hunan, hunan2012) %&gt;% \n  select(1:4, 7, 14)\n\nwrite_rds(hunan_GDPPC, \"Data/Geospatial/RDS/Hunan.rds\")\n\n\n\n\nReading the combined Hunan spatial data\n\n\nReveal Code\nhunan_GDPPC &lt;- read_rds(\"Data/Geospatial/RDS/Hunan.rds\")\n\n\n\n\n\nVisualising the GDPPC data in a choropleth map\n\n\nReveal Code\ntmap_mode(\"plot\")\n\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\", style = \"quantile\", palette = \"Blues\", title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by  county, Hunan province\", main.title.position = \"center\", main.title.size = 1.2, legend.height = 0.45, legend.width = 0.35, frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n\n\n\n\n\n\n\n\n\n\n\nDeriving the congruity weights using the QUEEN’s method\n\n\nReveal Code\nwm_q &lt;- hunan_GDPPC %&gt;% \n  mutate(nb = st_contiguity(geometry), wt = st_weights(nb, style = \"W\"), .before = 1)\n\n\n\n\nComputing the Moran’s I statistic\n\n\nReveal Code\nmoranI &lt;- global_moran(wm_q$GDPPC, wm_q$nb, wm_q$wt)\n\nglimpse(moranI)\n\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\n\nPerforming the Global Moran’s I test\n\n\nReveal Code\nglobal_moran_test(wm_q$GDPPC, wm_q$nb, wm_q$wt)\n\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351"
  }
]